{"cells":[{"cell_type":"code","source":["#\n","# Import Packages Required for this Notebook\n","#\n","from pyspark.sql import SparkSession\n","import pyodbc\n","import textwrap\n","\n","print(\"Successfully imported all packages for this notebook.\")\n","print(f\"PyOdbc drivers available: {pyodbc.drivers()}\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"768e7706-4523-4aec-a08d-c6aacbb45f6c"},{"cell_type":"code","source":["#\n","# Get required secrets from the key vault\n","#\n","vault_uri = \"https://kv-fabric-dev-eastus2.vault.azure.net/\"\n","\n","# Retrieve secret from Key Vault using mssparkutils\n","CLIENT_ID = mssparkutils.credentials.getSecret(vault_uri, \"CLIENT-ID\")\n","CLIENT_SECRET = mssparkutils.credentials.getSecret(vault_uri, \"CLIENT-SECRET\")\n","\n","# Use the secret securely without printing\n","print(\"Secrets retrieved successfully (not displayed for security reasons).\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"80ec2f04-4f73-4a97-9d38-4e6cd650c9a4"},{"cell_type":"code","source":["#\n","# Verify that key vault items cannot be viewed in clear text\n","#\n","print(f\"The value of the client ID is {CLIENT_ID}\")\n","print(f\"The value of the client secret is {CLIENT_SECRET}\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"09855d6a-3061-4182-be8b-cfc36693cc4a"},{"cell_type":"code","source":["#\n","# Configure run-time parameters for this notebook\n","#\n","DB_SCHEMA = \"dbo\"\n","SERVER = \"znbjxinpfs5u3cxz7s7bppllcq-ilhmootuvz6u5cwdltudlcrq34.datawarehouse.fabric.microsoft.com\"\n","DATABASE = \"AdventureWorks_Warehouse\"\n","\n","print(\"Successfully configured all paramaters for this run.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ad97af66-b6d8-4a0f-948d-0bdfb9ea4083"},{"cell_type":"code","source":["#\n","# Create the SQL connection to the Fabric Warehouse\n","#\n","conn_str = f\"\"\"\n","DRIVER={{ODBC Driver 18 for SQL Server}};\n","SERVER={SERVER};\n","DATABASE={DATABASE};\n","Initial Catalog={DB_SCHEMA};\n","Authentication=ActiveDirectoryServicePrincipal;\n","UID={CLIENT_ID};\n","PWD={CLIENT_SECRET};\n","\"\"\"\n","\n","# Create the connection\n","conn = pyodbc.connect(conn_str)\n","cursor = conn.cursor()\n","cursor.execute(\"SELECT @@SPID\")\n","spid = cursor.fetchone()[0]\n","cursor.close()\n","\n","print(f\"🔍 Successfully opened Connection ID (SPID): {spid} to the Fabic Warehouse.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"71eccf53-e25d-4020-89db-3a68178eeca7"},{"cell_type":"code","source":["#\n","# Get Foreign Key Relationships from the Fabric Warehouse\n","#\n","cursor = conn.cursor()\n","\n","cursor.execute(\"\"\"\n","WITH RelationshipCounts AS (\n","    SELECT \n","        fk.name AS FK_Name, fk_tab.name AS FK_Table, c1.name AS FK_Column, pk.name AS PK_Table, c2.name AS PK_Column,\n","        CASE \n","            -- One-to-One: FK column has a unique index AND PK column has a unique index\n","            WHEN fk_is_unique.index_id IS NOT NULL AND pk_is_unique.index_id IS NOT NULL THEN 'One-to-One'\n","            -- Many-to-One: FK is NOT unique, but PK has a unique index\n","            WHEN pk_is_unique.index_id IS NOT NULL THEN 'Many-to-One'\n","            -- Many-to-Many: Neither FK nor PK have unique constraints\n","            ELSE 'Many-to-Many'\n","        END AS Cardinality,\n","        COUNT(*) OVER (PARTITION BY pk.name, c2.name) AS PK_Reference_Count\n","    FROM sys.foreign_keys AS fk\n","    JOIN sys.foreign_key_columns AS fkc ON fk.object_id = fkc.constraint_object_id\n","    JOIN sys.tables AS fk_tab ON fk_tab.object_id = fkc.parent_object_id\n","    JOIN sys.columns AS c1 ON fkc.parent_column_id = c1.column_id \n","        AND fkc.parent_object_id = c1.object_id\n","    JOIN sys.tables AS pk ON pk.object_id = fkc.referenced_object_id\n","    JOIN sys.columns AS c2 ON fkc.referenced_column_id = c2.column_id \n","        AND fkc.referenced_object_id = c2.object_id\n","    -- Check if the referenced (PK) column is unique\n","    LEFT JOIN sys.index_columns AS pk_index_cols ON c2.object_id = pk_index_cols.object_id \n","        AND c2.column_id = pk_index_cols.column_id\n","    LEFT JOIN sys.indexes AS pk_is_unique ON pk_index_cols.object_id = pk_is_unique.object_id \n","        AND pk_index_cols.index_id = pk_is_unique.index_id \n","        AND pk_is_unique.is_unique = 1  \n","        AND pk_is_unique.type IN (1, 2) -- Clustered or Non-clustered Unique Index\n","    -- Check if the foreign key (FK) column is unique\n","    LEFT JOIN sys.index_columns AS fk_index_cols ON c1.object_id = fk_index_cols.object_id \n","        AND c1.column_id = fk_index_cols.column_id\n","    LEFT JOIN sys.indexes AS fk_is_unique ON fk_index_cols.object_id = fk_is_unique.object_id \n","        AND fk_index_cols.index_id = fk_is_unique.index_id \n","        AND fk_is_unique.is_unique = 1  \n","        AND fk_is_unique.type IN (1, 2) -- Clustered or Non-clustered Unique Index\n",")\n","SELECT \n","    FK_Name, FK_Table, FK_Column, PK_Table, PK_Column, Cardinality\n","FROM RelationshipCounts\n","WHERE Cardinality = 'Many-to-One' \n","AND PK_Reference_Count > 1    \n","ORDER BY FK_Name, PK_Table, PK_Column;\n","\"\"\")\n","\n","# Fetch the results\n","relationships = cursor.fetchall()\n","\n","print(f\"✅ Successfully extracted {len(relationships):,} forgein key relationships from the database '{DATABASE}'.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ba1feb7c-6a9d-471d-b6bd-4492152fd749"},{"cell_type":"code","source":["#\n","# Convert the results into TMDL format\n","#\n","tmdl_output = \"\"\n","\n","previous_fk_name = None\n","fk_name_counter = 1\n","\n","for row in relationships:\n","    fk_name = row.FK_Name\n","    from_table = row.FK_Table\n","    from_column = row.FK_Column\n","    to_table = row.PK_Table\n","    to_column = row.PK_Column\n","    cardinality = row.Cardinality\n","\n","    # Check if the current fk_name is the same as the previous one\n","    if fk_name == previous_fk_name:\n","        fk_name_counter += 1\n","        fk_name = f\"{fk_name}_{fk_name_counter}\"\n","    else:\n","        fk_name_counter = 1  # Reset counter for new FK_Name\n","\n","    previous_fk_name = row.FK_Name  # Store the original FK name for comparison\n","\n","    # Convert SQL cardinality description to TMDL format\n","    if cardinality == \"One-to-One\":\n","        from_cardinality = \"one\"\n","        to_cardinality = \"one\"\n","    elif cardinality == \"Many-to-One\":\n","        from_cardinality = \"many\"\n","        to_cardinality = \"one\"\n","    else:\n","        from_cardinality = \"many\"\n","        to_cardinality = \"many\"\n","\n","    # Format as TMDL relationship\n","    tmdl_output += textwrap.dedent(f\"\"\"\n","        relationship {fk_name}\n","            crossFilteringBehavior: oneDirection\n","            fromColumn: {from_table}.{from_column}\n","            toColumn: {to_table}.{to_column}\n","            fromCardinality: {from_cardinality}\n","            toCardinality: {to_cardinality}\n","    \"\"\")\n","\n","# Display the results\n","print(f\"✅ Successfully created TMDL output:\\n{(tmdl_output)}\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2e4eea30-20d3-406f-93d5-2deb859dcd62"},{"cell_type":"code","source":["#\n","# Close the SQL connection\n","#\n","conn.close()\n","print(\"✅ Successfully closed the SQL connection to the Fabic Warehouse.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c6966a98-8f63-4293-b132-68a880458b86"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"warehouse":{"known_warehouses":[{"id":"fcbdf876-ae83-4d7b-9fd4-4718c7bad3e2","type":"Datawarehouse"}],"default_warehouse":"fcbdf876-ae83-4d7b-9fd4-4718c7bad3e2"}}},"nbformat":4,"nbformat_minor":5}